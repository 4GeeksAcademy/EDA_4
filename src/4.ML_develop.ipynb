{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pickle\n",
    "from pickle import dump\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import math\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.feature_selection import f_regression, SelectKBest\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the labels from the CSV file\n",
    "y_train = pd.read_csv('/workspaces/EDA_4/data/processed/heart_prevalence_y_train.csv')\n",
    "y_test = pd.read_csv('/workspaces/EDA_4/data/processed/heart_prevalence_y_test.csv')\n",
    "X_train_norm = pd.read_csv('/workspaces/EDA_4/data/interim/heart_prevalence_X_train_std.csv')\n",
    "X_test_norm = pd.read_csv('/workspaces/EDA_4/data/interim/heart_prevalence_X_test_std.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore specific data conversion warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DataConversionWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Model Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The primary aim of this phase in the project is to leverage the capabilities of the linear regression model offered by the sklearn library. Our choice is substantiated by the insights gained during the Exploratory Data Analysis (EDA), which highlighted several variables exhibiting a distribution pattern aligning with the assumptions of linear regression in relation to our target variable.\n",
    "\n",
    "To optimize the model's effectiveness, a systematic approach will be adopted. We will employ a loop to iteratively determine the optimal value of 'k,' representing the number of variables the model should incorporate during the training process. This thoughtful selection process is crucial for enhancing the model's predictive accuracy and avoiding overfitting or underfitting scenarios.\n",
    "\n",
    "Once we ascertain the best configuration, we will persistently store it for future reference. Subsequently, we will reload this configuration and proceed with the model training phase. This training will involve comparing the model's predictions with the actual results from the test dataset, serving as a robust validation step to gauge the model's generalization capabilities.\n",
    "\n",
    "In essence, this meticulous procedure aims not only to identify the most effective model configuration but also to ensure its reliability and performance on unseen data. This iterative loop provides a systematic framework to fine-tune our model, fostering a more nuanced understanding of its predictive prowess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 0.2794007435544796\n",
      "Coefficient of Determination (R-squared): 0.9579028289114827\n",
      "The best model corresponds to 0.5 of selected features.\n"
     ]
    }
   ],
   "source": [
    "# Ignore specific data conversion warnings\n",
    "rmss = []  # Root Mean Squared Errors\n",
    "r2s = []   # R-squared values\n",
    "percents = [1, 0.8, 0.7, 0.6, 0.5]\n",
    "\n",
    "# Iterate over different percentages of selected features\n",
    "for p in percents:\n",
    "    # Select top features using SelectKBest with f_regression\n",
    "    selection_model = SelectKBest(f_regression, k=int(len(X_train_norm.columns) * p))\n",
    "    selection_model.fit(X_train_norm, y_train)\n",
    "    ix = selection_model.get_support()\n",
    "\n",
    "    # Transform datasets using selected features\n",
    "    X_train_sel = pd.DataFrame(selection_model.transform(X_train_norm), columns=X_train_norm.columns.values[ix])\n",
    "    X_test_sel = pd.DataFrame(selection_model.transform(X_test_norm), columns=X_test_norm.columns.values[ix])\n",
    "\n",
    "    # Save the selection model\n",
    "    dump(selection_model, open(f\"/workspaces/EDA_4/models/selection_model{p}.pk\", \"wb\"))\n",
    "\n",
    "    # Train linear regression model with selected features\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_sel, y_train)\n",
    "    y_pred = model.predict(X_train_sel)\n",
    "\n",
    "    # Evaluate and store performance metrics\n",
    "    rmss.append(math.sqrt(mean_squared_error(y_train, y_pred)))\n",
    "    r2s.append(r2_score(y_train, y_pred))\n",
    "\n",
    "# Find the index of the best models based on RMSE and R-squared\n",
    "best_rmss = rmss.index(max(rmss))\n",
    "best_r2s = r2s.index(max(r2s))\n",
    "\n",
    "# Print the results\n",
    "print(f\"Root Mean Squared Error: {rmss[best_rmss]}\")\n",
    "print(f\"Coefficient of Determination (R-squared): {r2s[best_r2s]}\")\n",
    "print(f\"The best model corresponds to {percents[best_rmss]} of selected features.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept (a): [8.37149865]\n",
      "Coefficients (b): [[-0.15549461  0.75459943 -0.27330536  0.53737403 -0.61739438  0.56593799]]\n",
      "--------------------------------\n",
      "Root Mean Squared Error on Train: 0.2794007435544796\n",
      "Coefficient of Determination on Train: 0.9340762739842043\n",
      "--------------------------------\n",
      "Root Mean Squared Error on Test: 0.5255850187397291\n",
      "Coefficient of Determination on Test: 0.8686706799451416\n",
      "--------------------------------\n",
      "The difference between Train and Test in Root Mean Squared Error is -0.2461842751852495.\n",
      "The difference between Train and Test in Coefficient of Determination is 0.06540559403906276.\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained feature selection model\n",
    "selection_model = pickle.load(open(\"/workspaces/EDA_4/models/selection_model0.5.pk\", \"rb\"))\n",
    "ix = selection_model.get_support()\n",
    "\n",
    "# Transform datasets using selected features\n",
    "X_train_sel = pd.DataFrame(selection_model.transform(X_train_norm), columns=X_train_norm.columns.values[ix])\n",
    "X_test_sel = pd.DataFrame(selection_model.transform(X_test_norm), columns=X_test_norm.columns.values[ix])\n",
    "\n",
    "# Train a linear regression model with the selected features\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_sel, y_train)\n",
    "\n",
    "# Print the intercept and coefficients of the linear regression model\n",
    "print(f\"Intercept (a): {model.intercept_}\")\n",
    "print(f\"Coefficients (b): {model.coef_}\")\n",
    "print(\"-\" * 32)\n",
    "\n",
    "# Predict and evaluate on the training set\n",
    "y_pred = model.predict(X_train_sel)\n",
    "e1 = math.sqrt(mean_squared_error(y_train, y_pred))\n",
    "r1 = r2_score(y_train, y_pred)\n",
    "print(f\"Root Mean Squared Error on Train: {e1}\")\n",
    "print(f\"Coefficient of Determination on Train: {r1}\")\n",
    "print(\"-\" * 32)\n",
    "\n",
    "# Predict and evaluate on the testing set\n",
    "y_pred = model.predict(X_test_sel)\n",
    "e2 = math.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Root Mean Squared Error on Test: {e2}\")\n",
    "print(f\"Coefficient of Determination on Test: {r2}\")\n",
    "print(\"-\" * 32)\n",
    "\n",
    "# Print the difference between training and testing performance metrics\n",
    "print(f\"The difference between Train and Test in Root Mean Squared Error is {e1 - e2}.\")\n",
    "print(f\"The difference between Train and Test in Coefficient of Determination is {r1 - r2}.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conlusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon completing this initial phase of model training, my foremost conclusion is the presence of overfitting. Consequently, it would be prudent to revisit both the Exploratory Data Analysis (EDA) and consider optimizing hyperparameters. Additionally, exploring the application of another model from the sklearn library is a viable avenue.\n",
    "\n",
    "For the sake of thorough practice, I intend to conduct a separate training session in a new notebook employing an alternative model. In this subsequent endeavor, I will delve into hyperparameter optimization, aiming to mitigate overfitting and enhance the model's generalization performance. This approach aligns with best practices for model development and will contribute to a more robust and reliable predictive model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
